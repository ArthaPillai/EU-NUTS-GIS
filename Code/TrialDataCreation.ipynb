{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c58bc6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apillai\\AppData\\Local\\Temp\\ipykernel_1216\\1010902005.py:4: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  data = pd.read_stata('C:/Users/apillai/OneDrive - World Justice Project/Documents/GitHub/EU-NUTS-GIS/Data/EU_GPP_2024.dta')\n",
      "C:\\Users\\apillai\\AppData\\Local\\Temp\\ipykernel_1216\\1010902005.py:4: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  data = pd.read_stata('C:/Users/apillai/OneDrive - World Justice Project/Documents/GitHub/EU-NUTS-GIS/Data/EU_GPP_2024.dta')\n",
      "C:\\Users\\apillai\\AppData\\Local\\Temp\\ipykernel_1216\\1010902005.py:4: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  data = pd.read_stata('C:/Users/apillai/OneDrive - World Justice Project/Documents/GitHub/EU-NUTS-GIS/Data/EU_GPP_2024.dta')\n",
      "C:\\Users\\apillai\\AppData\\Local\\Temp\\ipykernel_1216\\1010902005.py:4: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  data = pd.read_stata('C:/Users/apillai/OneDrive - World Justice Project/Documents/GitHub/EU-NUTS-GIS/Data/EU_GPP_2024.dta')\n",
      "C:\\Users\\apillai\\AppData\\Local\\Temp\\ipykernel_1216\\1010902005.py:4: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  data = pd.read_stata('C:/Users/apillai/OneDrive - World Justice Project/Documents/GitHub/EU-NUTS-GIS/Data/EU_GPP_2024.dta')\n",
      "C:\\Users\\apillai\\AppData\\Local\\Temp\\ipykernel_1216\\1010902005.py:4: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  data = pd.read_stata('C:/Users/apillai/OneDrive - World Justice Project/Documents/GitHub/EU-NUTS-GIS/Data/EU_GPP_2024.dta')\n",
      "C:\\Users\\apillai\\AppData\\Local\\Temp\\ipykernel_1216\\1010902005.py:4: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  data = pd.read_stata('C:/Users/apillai/OneDrive - World Justice Project/Documents/GitHub/EU-NUTS-GIS/Data/EU_GPP_2024.dta')\n",
      "C:\\Users\\apillai\\AppData\\Local\\Temp\\ipykernel_1216\\1010902005.py:4: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  data = pd.read_stata('C:/Users/apillai/OneDrive - World Justice Project/Documents/GitHub/EU-NUTS-GIS/Data/EU_GPP_2024.dta')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'country_name_off' contains non-ASCII characters\n",
      "Column 'nuts_ltn' contains non-ASCII characters\n",
      "Column 'income_text' contains non-ASCII characters\n",
      "Column 'income_cur' contains non-ASCII characters\n",
      "Column 'KNW_rol_1' contains non-ASCII characters\n",
      "Column 'KNW_rol_2' contains non-ASCII characters\n",
      "Column 'KNW_rol_3' contains non-ASCII characters\n",
      "Column 'KNW_justice_1' contains non-ASCII characters\n",
      "Column 'KNW_justice_2' contains non-ASCII characters\n",
      "Column 'KNW_justice_3' contains non-ASCII characters\n",
      "Column 'KNW_governance_1' contains non-ASCII characters\n",
      "Column 'KNW_governance_2' contains non-ASCII characters\n",
      "Column 'KNW_governance_3' contains non-ASCII characters\n",
      "Column 'relig' contains non-ASCII characters\n",
      "Column 'ethni' contains non-ASCII characters\n",
      "Column 'voteintention' contains non-ASCII characters\n",
      "Column 'city' contains non-ASCII characters\n",
      "Column 'region' contains non-ASCII characters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data (pandas will automatically fall back to Latin-1 encoding)\n",
    "data = pd.read_stata('C:/Users/apillai/OneDrive - World Justice Project/Documents/GitHub/EU-NUTS-GIS/Data/EU_GPP_2024.dta')\n",
    "\n",
    "# Function to detect non-ASCII characters in a string\n",
    "def contains_non_ascii(s):\n",
    "    return any(ord(i) > 127 for i in str(s))\n",
    "\n",
    "# Apply this function to each column and print columns with non-ASCII characters\n",
    "for column in data.select_dtypes(include='object').columns:\n",
    "    if data[column].apply(contains_non_ascii).any():\n",
    "        print(f\"Column '{column}' contains non-ASCII characters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b593d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8630e218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected encoding: utf-8\n"
     ]
    }
   ],
   "source": [
    "import chardet\n",
    "# Convert DataFrame to bytes and detect the encoding\n",
    "data = data.to_csv(index=False).encode()\n",
    "result = chardet.detect(data)\n",
    "\n",
    "# Print the detected encoding\n",
    "print(\"Detected encoding:\", result['encoding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59a099ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "byte indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Convert non-string labels to strings\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcountry_name_off\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcountry_name_off\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m) \n\u001b[0;32m      4\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnuts_ltn\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnuts_ltn\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)  \n\u001b[0;32m      5\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincome_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincome_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)  \n",
      "\u001b[1;31mTypeError\u001b[0m: byte indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# Convert non-string labels to strings\n",
    "\n",
    "data['country_name_off'] = data['country_name_off'].astype(str) \n",
    "data['nuts_ltn'] = data['nuts_ltn'].astype(str)  \n",
    "data['income_text'] = data['income_text'].astype(str)  \n",
    "data['income_cur'] = data['income_cur'].astype(str)  \n",
    "data['KNW_rol_1'] = data['KNW_rol_1'].astype(str) \n",
    "data['KNW_rol_2'] = data['KNW_rol_2'].astype(str) \n",
    "data['KNW_rol_3'] = data['KNW_rol_3'].astype(str) \n",
    "data['KNW_justice_1'] = data['KNW_justice_1'].astype(str) \n",
    "data['KNW_justice_2'] = data['KNW_justice_2'].astype(str)  \n",
    "data['KNW_justice_3'] = data['KNW_justice_3'].astype(str)  \n",
    "data['relig'] = data['relig'].astype(str)  \n",
    "data['ethni'] = data['ethni'].astype(str) \n",
    "data['voteintention'] = data['voteintention'].astype(str) \n",
    "data['city'] = data['city'].astype(str) \n",
    "data['region'] = data['region'].astype(str) \n",
    "\n",
    "# Specify the path where you want to save the .dta file\n",
    "file_path = \"C:/Users/apillai/OneDrive - World Justice Project/Documents/GitHub/EU-NUTS-GIS/Data/TrialData.dta\"\n",
    "\n",
    "# Save the DataFrame as a .dta file\n",
    "data.to_stata(file_path, version=118, write_index=False)  \n",
    "\n",
    "print(\"Subset data saved as\", file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253644bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data (pandas will automatically fall back to Latin-1 encoding)\n",
    "df = pd.read_stata('C:/Users/apillai/OneDrive - World Justice Project/Documents/GitHub/EU-NUTS-GIS/Data/TrialData.dta')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0962907",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea11088",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('C:/Users/apillai/OneDrive - World Justice Project/Documents/GitHub/EU-NUTS-GIS/Data/TrialData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e0ba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.country_name_off\t.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083c7841",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.country_name_ltn\t.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a24155",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
